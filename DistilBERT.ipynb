{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "DistilBERT.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMcBMkbyD+jmuAgwSW4FwsK",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "11ef220bfb9b4d299ee965e3f1d52786": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_69a4729e6aae4454ad9b4a67c9144f1e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_6799ac727f79413db6438e73f4e5dec8",
              "IPY_MODEL_d4e3e13a51884562b0f69136bc4aea8b"
            ]
          }
        },
        "69a4729e6aae4454ad9b4a67c9144f1e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6799ac727f79413db6438e73f4e5dec8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c911b46e8e57451ebbcf8005f51a6b3b",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ea1f3e06d9e44be8a11ccb50526900ea"
          }
        },
        "d4e3e13a51884562b0f69136bc4aea8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a0aab56123b8462a9338a1f1f79f34cd",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 3.79MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3328d081ac904c0999c0f9601854eaef"
          }
        },
        "c911b46e8e57451ebbcf8005f51a6b3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ea1f3e06d9e44be8a11ccb50526900ea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a0aab56123b8462a9338a1f1f79f34cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3328d081ac904c0999c0f9601854eaef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LukrecijaTudor/NLP/blob/main/DistilBERT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J5ySplHEC8XE",
        "outputId": "fc968925-ce7e-4aad-e945-e1d77c85745f"
      },
      "source": [
        "pip install pycld2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pycld2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/21/d2/8b0def84a53c88d0eb27c67b05269fbd16ad68df8c78849e7b5d65e6aec3/pycld2-0.41.tar.gz (41.4MB)\n",
            "\u001b[K     |████████████████████████████████| 41.4MB 77kB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pycld2\n",
            "  Building wheel for pycld2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycld2: filename=pycld2-0.41-cp36-cp36m-linux_x86_64.whl size=9833532 sha256=2b6b0df135042f171bd1fc3242453a417724366837e453feac3a38ee3ff4c385\n",
            "  Stored in directory: /root/.cache/pip/wheels/c6/8f/e9/08a1a8932a490175bd140206cd86a3dbcfc70498100de11079\n",
            "Successfully built pycld2\n",
            "Installing collected packages: pycld2\n",
            "Successfully installed pycld2-0.41\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LshA6z0PELl-",
        "outputId": "74b0a3d5-e746-405e-e22f-76f6365f161f"
      },
      "source": [
        "pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/88/b1/41130a228dd656a1a31ba281598a968320283f48d42782845f6ba567f00b/transformers-4.2.2-py3-none-any.whl (1.8MB)\n",
            "\r\u001b[K     |▏                               | 10kB 18.1MB/s eta 0:00:01\r\u001b[K     |▍                               | 20kB 25.2MB/s eta 0:00:01\r\u001b[K     |▋                               | 30kB 22.5MB/s eta 0:00:01\r\u001b[K     |▊                               | 40kB 20.8MB/s eta 0:00:01\r\u001b[K     |█                               | 51kB 21.4MB/s eta 0:00:01\r\u001b[K     |█▏                              | 61kB 16.2MB/s eta 0:00:01\r\u001b[K     |█▎                              | 71kB 16.9MB/s eta 0:00:01\r\u001b[K     |█▌                              | 81kB 17.7MB/s eta 0:00:01\r\u001b[K     |█▊                              | 92kB 16.1MB/s eta 0:00:01\r\u001b[K     |█▉                              | 102kB 17.2MB/s eta 0:00:01\r\u001b[K     |██                              | 112kB 17.2MB/s eta 0:00:01\r\u001b[K     |██▎                             | 122kB 17.2MB/s eta 0:00:01\r\u001b[K     |██▍                             | 133kB 17.2MB/s eta 0:00:01\r\u001b[K     |██▋                             | 143kB 17.2MB/s eta 0:00:01\r\u001b[K     |██▉                             | 153kB 17.2MB/s eta 0:00:01\r\u001b[K     |███                             | 163kB 17.2MB/s eta 0:00:01\r\u001b[K     |███▏                            | 174kB 17.2MB/s eta 0:00:01\r\u001b[K     |███▍                            | 184kB 17.2MB/s eta 0:00:01\r\u001b[K     |███▌                            | 194kB 17.2MB/s eta 0:00:01\r\u001b[K     |███▊                            | 204kB 17.2MB/s eta 0:00:01\r\u001b[K     |████                            | 215kB 17.2MB/s eta 0:00:01\r\u001b[K     |████                            | 225kB 17.2MB/s eta 0:00:01\r\u001b[K     |████▎                           | 235kB 17.2MB/s eta 0:00:01\r\u001b[K     |████▌                           | 245kB 17.2MB/s eta 0:00:01\r\u001b[K     |████▋                           | 256kB 17.2MB/s eta 0:00:01\r\u001b[K     |████▉                           | 266kB 17.2MB/s eta 0:00:01\r\u001b[K     |█████                           | 276kB 17.2MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 286kB 17.2MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 296kB 17.2MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 307kB 17.2MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 317kB 17.2MB/s eta 0:00:01\r\u001b[K     |██████                          | 327kB 17.2MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 337kB 17.2MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 348kB 17.2MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 358kB 17.2MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 368kB 17.2MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 378kB 17.2MB/s eta 0:00:01\r\u001b[K     |███████                         | 389kB 17.2MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 399kB 17.2MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 409kB 17.2MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 419kB 17.2MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 430kB 17.2MB/s eta 0:00:01\r\u001b[K     |████████                        | 440kB 17.2MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 450kB 17.2MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 460kB 17.2MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 471kB 17.2MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 481kB 17.2MB/s eta 0:00:01\r\u001b[K     |█████████                       | 491kB 17.2MB/s eta 0:00:01\r\u001b[K     |█████████                       | 501kB 17.2MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 512kB 17.2MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 522kB 17.2MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 532kB 17.2MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 542kB 17.2MB/s eta 0:00:01\r\u001b[K     |██████████                      | 552kB 17.2MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 563kB 17.2MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 573kB 17.2MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 583kB 17.2MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 593kB 17.2MB/s eta 0:00:01\r\u001b[K     |███████████                     | 604kB 17.2MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 614kB 17.2MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 624kB 17.2MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 634kB 17.2MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 645kB 17.2MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 655kB 17.2MB/s eta 0:00:01\r\u001b[K     |████████████                    | 665kB 17.2MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 675kB 17.2MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 686kB 17.2MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 696kB 17.2MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 706kB 17.2MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 716kB 17.2MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 727kB 17.2MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 737kB 17.2MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 747kB 17.2MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 757kB 17.2MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 768kB 17.2MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 778kB 17.2MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 788kB 17.2MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 798kB 17.2MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 808kB 17.2MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 819kB 17.2MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 829kB 17.2MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 839kB 17.2MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 849kB 17.2MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 860kB 17.2MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 870kB 17.2MB/s eta 0:00:01\r\u001b[K     |████████████████                | 880kB 17.2MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 890kB 17.2MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 901kB 17.2MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 911kB 17.2MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 921kB 17.2MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 931kB 17.2MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 942kB 17.2MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 952kB 17.2MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 962kB 17.2MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 972kB 17.2MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 983kB 17.2MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 993kB 17.2MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 1.0MB 17.2MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 1.0MB 17.2MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 1.0MB 17.2MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 1.0MB 17.2MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 1.0MB 17.2MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 1.1MB 17.2MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 1.1MB 17.2MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 1.1MB 17.2MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 1.1MB 17.2MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 1.1MB 17.2MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 1.1MB 17.2MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 1.1MB 17.2MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 1.1MB 17.2MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 1.1MB 17.2MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 1.1MB 17.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 1.2MB 17.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 1.2MB 17.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 1.2MB 17.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 1.2MB 17.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 1.2MB 17.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 1.2MB 17.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 1.2MB 17.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 1.2MB 17.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 1.2MB 17.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 1.2MB 17.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 1.3MB 17.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 1.3MB 17.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 1.3MB 17.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 1.3MB 17.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 1.3MB 17.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 1.3MB 17.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 1.3MB 17.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 1.3MB 17.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 1.3MB 17.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 1.4MB 17.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 1.4MB 17.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 1.4MB 17.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.4MB 17.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 1.4MB 17.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 1.4MB 17.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 1.4MB 17.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 1.4MB 17.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.4MB 17.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 1.4MB 17.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 1.5MB 17.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 1.5MB 17.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 1.5MB 17.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.5MB 17.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.5MB 17.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 1.5MB 17.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 1.5MB 17.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 1.5MB 17.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 1.5MB 17.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.5MB 17.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 1.6MB 17.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 1.6MB 17.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 1.6MB 17.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 1.6MB 17.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.6MB 17.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 1.6MB 17.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 1.6MB 17.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 1.6MB 17.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.6MB 17.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 1.6MB 17.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.7MB 17.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 1.7MB 17.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 1.7MB 17.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 1.7MB 17.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 1.7MB 17.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.7MB 17.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 1.7MB 17.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 1.7MB 17.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 1.7MB 17.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 1.8MB 17.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.8MB 17.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.8MB 17.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.8)\n",
            "Collecting tokenizers==0.9.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/1c/e789a8b12e28be5bc1ce2156cf87cb522b379be9cadc7ad8091a4cc107c4/tokenizers-0.9.4-cp36-cp36m-manylinux2010_x86_64.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 56.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from transformers) (3.4.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 55.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.0.0)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893261 sha256=ba4417dfcdaa8b7b8d24d833be97273f17aaa72c4cff28e1e3aebd3b7dacc840\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.43 tokenizers-0.9.4 transformers-4.2.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cdc-FMn3ETnF"
      },
      "source": [
        "import torch\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_ZC70opCiXY"
      },
      "source": [
        "import pandas as pd\n",
        "import pycld2 as cld2\n",
        "#import ndjson\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DUkxkeaAECoW"
      },
      "source": [
        "#baseline\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import GridSearchCV"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fFKZ4uiQCjpx"
      },
      "source": [
        "acronyms = pd.read_excel(\"/content/kratice.xlsx\")\n",
        "acronyms = acronyms.rename(columns={'kratice':'acronym','Unnamed: 1':'replacement'})\n",
        "document = pd.read_csv(\"/content/qa06_all.csv\")\n",
        "document = document.rename(columns={'qa06id': 'id', 'qa06name':'title', 'qa06wher':'location','qa06dsc':'report'})\n",
        "document_risk=pd.read_csv(\"/content/qa06_only_having_risk_valuesl.csv\")\n",
        "document_risk = document_risk.rename(columns={'qa06id': 'id', 'qa06name':'title', 'qa06wher':'location','qa06dsc':'report','ty26colo':'label','ty26fakt':'factor'})\n",
        "def acronyms_to_words (txt):\n",
        "    #acronyms = pd.read_excel(\"/Users/Lukre/Desktop/D/kratice.xlsx\")\n",
        "    #acronyms = acronyms.rename(columns={'kratice':'acronym','Unnamed: 1':'replacement'})\n",
        "    for i in range (len(acronyms)):\n",
        "        txt=txt.replace(' ' + acronyms.acronym[i] + ' ',' ' + acronyms.replacement[i] + ' ')\n",
        "    return txt\n",
        "\n",
        "def isNaN(string):\n",
        "    return string != string\n",
        "def prep_doc__for_bert_classification(document):\n",
        "    \n",
        "  doc = pd.DataFrame(columns=['report','accident','label'])\n",
        "    \n",
        "  for i in range(len(document)):\n",
        "       \n",
        "      if isNaN(document.report[i]):\n",
        "          continue\n",
        "      isReliable, textBytesFound, details=cld2.detect(document.report[i])\n",
        "      \n",
        "      if not isReliable:\n",
        "                  continue\n",
        "      if details[0][0]!='ENGLISH':\n",
        "          continue\n",
        "      txt=acronyms_to_words (document.report[i])\n",
        "      if (document.factor[i]==1):\n",
        "                pom_2=0\n",
        "                pom='no accident outcome'\n",
        "      \n",
        "      if (document.factor[i] in (2,4,20,100)):\n",
        "                pom_2=1\n",
        "                pom='minor injuries or damage'\n",
        "      if (document.factor[i] in (10,50,21,102,101,502,500)):\n",
        "                pom_2=2\n",
        "                pom='major or catastrophic accident'\n",
        "\n",
        "      doc=doc.append({'report': txt,'accident': pom,'label': pom_2},ignore_index=True)\n",
        "\n",
        "  return doc\n",
        "def train_val_test_split_ (doc,label,rnd=42,size=0.2):\n",
        "  X_train_1, X_test, y_train_1, y_test = train_test_split(doc.index.values, \n",
        "                                                  doc.label.values, \n",
        "                                                  test_size=size, \n",
        "                                                  random_state=rnd, \n",
        "                                                  stratify=doc.label.values)\n",
        "  \n",
        "  pom = pd.DataFrame(columns=['X','y'])\n",
        "  pom['X']=X_train_1\n",
        "  pom['y']=y_train_1\n",
        "\n",
        "  X_train, X_val, y_train, y_val = train_test_split(pom.X.values, \n",
        "                                                  pom.y.values, \n",
        "                                                  test_size=size, \n",
        "                                                  random_state=rnd, \n",
        "                                                  stratify=pom.y.values) \n",
        "  doc['data_type'] = ['not_set']*doc.shape[0]\n",
        "\n",
        "\n",
        "  doc.loc[X_train, 'data_type'] = 'train'\n",
        "  doc.loc[X_val, 'data_type'] = 'val' \n",
        "  doc.loc[X_test, 'data_type'] = 'test'\n",
        "  return doc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KwgRw8UHC5xh"
      },
      "source": [
        "doc_bert = prep_doc__for_bert_classification (document_risk)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_dPTz1xC5B5"
      },
      "source": [
        "texts=doc_bert['report'].to_list()\n",
        "labels=doc_bert['accident'].to_list()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0mvxnrd5BISJ"
      },
      "source": [
        "main_txt, test_txt, main_labels, test_labels = train_test_split(texts, labels, test_size=0.1, random_state=1)\n",
        "train_txt, val_txt, train_labels, val_labels = train_test_split(main_texts, rest_labels, test_size=0.1, random_state=1)\n",
        "\n",
        "print(\"Train size:\", len(train_txt))\n",
        "print(\"Val size:\", len(val_txt))\n",
        "print(\"Test size:\", len(test_txt))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A0z6BnKmDxw4",
        "outputId": "bd88b2aa-ee28-45d2-a3f4-99a0a7c422f5"
      },
      "source": [
        "class_names = list(set(labels))\n",
        "label_ids = {label: id for id, label in enumerate(class_names)}\n",
        "print(label_ids)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'minor injuries or damage': 0, 'no accident outcome': 1, 'major or catastrophic accident': 2}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4LzMBxEqEfrC"
      },
      "source": [
        "MODEL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nktvJVzFD6C_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "11ef220bfb9b4d299ee965e3f1d52786",
            "69a4729e6aae4454ad9b4a67c9144f1e",
            "6799ac727f79413db6438e73f4e5dec8",
            "d4e3e13a51884562b0f69136bc4aea8b",
            "c911b46e8e57451ebbcf8005f51a6b3b",
            "ea1f3e06d9e44be8a11ccb50526900ea",
            "a0aab56123b8462a9338a1f1f79f34cd",
            "3328d081ac904c0999c0f9601854eaef"
          ]
        },
        "outputId": "8954092c-f4bf-4dc6-8399-aafb8314419a"
      },
      "source": [
        "from transformers import DistilBertTokenizer\n",
        "\n",
        "BERT_MODEL = \"distilbert-base-uncased\"\n",
        "tokenizer = DistilBertTokenizer.from_pretrained(BERT_MODEL)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "11ef220bfb9b4d299ee965e3f1d52786",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8oaBVBEyEp3B"
      },
      "source": [
        "from transformers import DistilBertForSequenceClassification\n",
        "\n",
        "model = DistilBertForSequenceClassification.from_pretrained(BERT_MODEL, num_labels = len(label_ids))\n",
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yXei040uFGrp"
      },
      "source": [
        "import logging\n",
        "\n",
        "logging.basicConfig(format = '%(asctime)s - %(levelname)s - %(name)s -   %(message)s',\n",
        "                    datefmt = '%m/%d/%Y %H:%M:%S',\n",
        "                    level = logging.INFO)\n",
        "logger = logging.getLogger(__name__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rSnKpNcXFtN5"
      },
      "source": [
        "inputi modela"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o6nTINnvFxYR"
      },
      "source": [
        "MAX_SEQ_LENGTH = 128 #100, 128, 256, 512\n",
        "BATCH_SIZE = 16  #16, 32"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AMbbTvMVFk69"
      },
      "source": [
        "class BertInput(object):\n",
        "\n",
        "    def __init__(self, text, input_ids, input_mask, label_id):\n",
        "        self.text = text\n",
        "        self.input_ids = input_ids\n",
        "        self.input_mask = input_mask\n",
        "        self.label_id = label_id\n",
        "        \n",
        "\n",
        "def input_data(example_texts, example_labels, label_ids, max_seq_length, tokenizer, verbose=0):\n",
        "    \n",
        "    input_items = []\n",
        "    examples = zip(example_texts, example_labels)\n",
        "    for (ex_index, (text, label)) in enumerate(examples):\n",
        "\n",
        "        input_ids = tokenizer.encode(f\"[CLS] {text} [SEP]\")\n",
        "        if len(input_ids) > max_seq_length:\n",
        "            input_ids = input_ids[:max_seq_length]\n",
        "\n",
        "        #segment_ids = [0] * len(input_ids)  --kod BERT modela se uvodi i svi se postave na vrijednost 1\n",
        "\n",
        "        input_mask = [1] * len(input_ids)\n",
        "\n",
        "        padding = [0] * (max_seq_length - len(input_ids)) # truncate i padding također su moguće opcije kod tokenizatora\n",
        "        input_ids += padding\n",
        "        input_mask += padding\n",
        "        #segment_ids += padding --kod BERT modela\n",
        "\n",
        "        #provjera valjanosti\n",
        "        assert len(input_ids) == max_seq_length \n",
        "        assert len(input_mask) == max_seq_length\n",
        "        #assert len(segment_ids) == max_seq_length\n",
        "\n",
        "        label_id = label_ids[label]\n",
        "\n",
        "        input_items.append(\n",
        "            BertInput(text=text,\n",
        "                          input_ids=input_ids,\n",
        "                          input_mask=input_mask,\n",
        "                          label_id=label_id))\n",
        "\n",
        "        \n",
        "    return input_items"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_FfsJS9oFv7r",
        "outputId": "5539a98c-f813-44f7-f333-c0f76bdb84bc"
      },
      "source": [
        "train_features = input_data(train_txt, train_labels, label_ids, MAX_SEQ_LENGTH, tokenizer, verbose=0)\n",
        "val_features = input_data(val_txt, val_labels, label_ids, MAX_SEQ_LENGTH, tokenizer)\n",
        "test_features = input_data(test_txt, test_labels, label_ids, MAX_SEQ_LENGTH, tokenizer)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (513 > 512). Running this sequence through the model will result in indexing errors\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WgVQ5l5rifzl"
      },
      "source": [
        "import pickle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f25jqFWRiXjL"
      },
      "source": [
        "  with open ('train_input_distilbert.csv','wb') as f:\n",
        "    pickle.dump(train_features,f)\n",
        "  with open ('val_input_distilbert.csv','wb') as g:\n",
        "    pickle.dump(dev_features,g)\n",
        "  with open ('test_input_distilbert.csv','wb') as h:\n",
        "    pickle.dump(test_features,h)\n",
        "  with open ('train_input_distilbert.csv','rb') as i:\n",
        "    d=pickle.load(i)\n",
        "  with open ('val_input_distilbert.csv','rb') as j:\n",
        "    e=pickle.load(j)\n",
        "  with open ('test_input_distilbert.csv','rb') as k:\n",
        "    l=pickle.load(k)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EqtFhMQHGd6z"
      },
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, SequentialSampler\n",
        "\n",
        "def get_data_loader(features, max_seq_length, batch_size, shuffle=True): \n",
        "\n",
        "    all_input_ids = torch.tensor([f.input_ids for f in features], dtype=torch.long)\n",
        "    all_input_mask = torch.tensor([f.input_mask for f in features], dtype=torch.long)\n",
        "    #all_segment_ids = torch.tensor([f.segment_ids for f in features], dtype=torch.long)\n",
        "    all_label_ids = torch.tensor([f.label_id for f in features], dtype=torch.long)\n",
        "    data = TensorDataset(all_input_ids, all_input_mask, all_label_ids)\n",
        "\n",
        "    dataloader = DataLoader(data, shuffle=shuffle, batch_size=batch_size)\n",
        "    return dataloader\n",
        "\n",
        "train_dataloader = get_data_loader(train_features, MAX_SEQ_LENGTH, BATCH_SIZE, shuffle=True)\n",
        "val_dataloader = get_data_loader(val_features, MAX_SEQ_LENGTH, BATCH_SIZE, shuffle=False)\n",
        "test_dataloader = get_data_loader(test_features, MAX_SEQ_LENGTH, BATCH_SIZE, shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qbl0XJmQG70i"
      },
      "source": [
        "def evaluation(model, dataloader):\n",
        "    model.eval()\n",
        "    \n",
        "    eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "    predicted_labels, correct_labels = [], []\n",
        "\n",
        "    for step, batch in enumerate(tqdm(dataloader, desc=\"Evaluation iteration\")):\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        input_ids, input_mask, label_ids = batch\n",
        "\n",
        "        with torch.no_grad():\n",
        "            tmp_eval_loss, logits = model(input_ids, attention_mask=input_mask, labels=label_ids,return_dict=False)\n",
        "\n",
        "        outputs = np.argmax(logits.to('cpu'), axis=1)\n",
        "        label_ids = label_ids.to('cpu').numpy()\n",
        "\n",
        "        predicted_labels += list(outputs)\n",
        "        correct_labels += list(label_ids)\n",
        "        \n",
        "        eval_loss += tmp_eval_loss.mean().item()\n",
        "        nb_eval_steps += 1\n",
        "\n",
        "    eval_loss = eval_loss / nb_eval_steps\n",
        "    \n",
        "    correct_labels = np.array(correct_labels)\n",
        "    predicted_labels = np.array(predicted_labels)\n",
        "        \n",
        "    return eval_loss, correct_labels, predicted_labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GN-nTkuqHkY0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQbZ0dT_HOa7"
      },
      "source": [
        "from transformers.optimization import AdamW\n",
        "from transformers.optimization import get_linear_schedule_with_warmup\n",
        "\n",
        "GRADIENT_ACCUMULATION_STEPS = 1\n",
        "NUM_TRAIN_EPOCHS = 5 #10 #20\n",
        "LEARNING_RATE = 1e-5 #5e-5\n",
        "WARMUP_PROPORTION = 0.1\n",
        "MAX_GRAD_NORM = 5\n",
        "\n",
        "num_train_steps = int(len(train_dataloader.dataset) / BATCH_SIZE / GRADIENT_ACCUMULATION_STEPS * NUM_TRAIN_EPOCHS)\n",
        "num_warmup_steps = int(WARMUP_PROPORTION * num_train_steps)\n",
        "\n",
        "param_optimizer = list(model.named_parameters())\n",
        "no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
        "optimizer_grouped_parameters = [\n",
        "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
        "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
        "    ]\n",
        "\n",
        "optimizer = AdamW(optimizer_grouped_parameters, lr=LEARNING_RATE, correct_bias=False)\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=num_warmup_steps, num_training_steps=num_train_steps)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q4MfQjCQLzwU"
      },
      "source": [
        "import torch\n",
        "import os\n",
        "from tqdm import trange\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "from sklearn.metrics import classification_report, precision_recall_fscore_support"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iByV7PlbHbvw"
      },
      "source": [
        "loss_history = []\n",
        "no_improvement = 0\n",
        "for _ in trange(int(NUM_TRAIN_EPOCHS), desc=\"Epoch\"):\n",
        "    model.train()\n",
        "    tr_loss = 0\n",
        "    nb_tr_examples, nb_tr_steps = 0, 0\n",
        "    for step, batch in enumerate(tqdm(train_dataloader, desc=\"Training iteration\")):\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        input_ids, input_mask, label_ids = batch\n",
        "\n",
        "        outputs = model(input_ids, attention_mask=input_mask, labels=label_ids, return_dict=False)\n",
        "        loss = outputs[0]\n",
        "\n",
        "        if GRADIENT_ACCUMULATION_STEPS > 1:\n",
        "            loss = loss / GRADIENT_ACCUMULATION_STEPS\n",
        "\n",
        "        loss.backward()\n",
        "        tr_loss += loss.item()\n",
        "\n",
        "        if (step + 1) % GRADIENT_ACCUMULATION_STEPS == 0:\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), MAX_GRAD_NORM)  \n",
        "            \n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "            scheduler.step()\n",
        "            \n",
        "    val_loss, _, _ = evaluation(model, val_dataloader)\n",
        "    \n",
        "    print(\"Loss history:\", loss_history)\n",
        "    print(\"Val loss:\", dev_loss)\n",
        "    \n",
        "    if len(loss_history) == 0 or val_loss < min(loss_history):\n",
        "        no_improvement = 0\n",
        "        model_to_save = model.module if hasattr(model, 'module') else model\n",
        "\n",
        "    else:\n",
        "        no_improvement += 1\n",
        "\n",
        "   loss_history.append(val_loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xyDU7YlnJDBh"
      },
      "source": [
        "model = model_to_save\n",
        "model.to(device)\n",
        "\n",
        "model.eval()\n",
        "\n",
        "_, train_correct, train_predicted = evaluation(model, train_dataloader)\n",
        "_, val_correct, val_predicted = evaluation(model, val_dataloader)\n",
        "_, test_correct, test_predicted = evaluation(model, test_dataloader)\n",
        "\n",
        "print(\"Training performance:\", precision_recall_fscore_support(train_correct, train_predicted, average=\"micro\"))\n",
        "print(\"Development performance:\", precision_recall_fscore_support(val_correct, val_predicted, average=\"micro\"))\n",
        "print(\"Test performance:\", precision_recall_fscore_support(test_correct, test_predicted, average=\"micro\"))\n",
        "\n",
        "bert_accuracy = np.mean(test_predicted == test_correct)\n",
        "\n",
        "print(classification_report(test_correct, test_predicted, target_names=target_names))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQzysEtCmeLo"
      },
      "source": [
        "import sklearn\n",
        "y_test = test_correct\n",
        "y_pred = test_predicted"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kXGf8IL2mere"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "confusion = confusion_matrix(y_test, y_pred)\n",
        "print('Confusion Matrix\\n')\n",
        "print(confusion)\n",
        "\n",
        "#importing accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "print('\\nAccuracy: {:.2f}\\n'.format(accuracy_score(y_test, y_pred)))\n",
        "\n",
        "print('Micro Precision: {:.2f}'.format(precision_score(y_test, y_pred, average='micro')))\n",
        "print('Micro Recall: {:.2f}'.format(recall_score(y_test, y_pred, average='micro')))\n",
        "print('Micro F1-score: {:.2f}\\n'.format(f1_score(y_test, y_pred, average='micro')))\n",
        "\n",
        "print('Macro Precision: {:.2f}'.format(precision_score(y_test, y_pred, average='macro')))\n",
        "print('Macro Recall: {:.2f}'.format(recall_score(y_test, y_pred, average='macro')))\n",
        "print('Macro F1-score: {:.2f}\\n'.format(f1_score(y_test, y_pred, average='macro')))\n",
        "\n",
        "print('Weighted Precision: {:.2f}'.format(precision_score(y_test, y_pred, average='weighted')))\n",
        "print('Weighted Recall: {:.2f}'.format(recall_score(y_test, y_pred, average='weighted')))\n",
        "print('Weighted F1-score: {:.2f}'.format(f1_score(y_test, y_pred, average='weighted')))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_S8bIxgJmkLg"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}